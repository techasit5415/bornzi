"""
PDF Processing and Vector Store Management
"""
import os
import tempfile
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from embeddings_config import EmbeddingFactory, get_recommended_model


def get_dynamic_chunk_params(total_chars, num_pages):
    """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì chunk size ‡πÅ‡∏ö‡∏ö dynamic - ‡πÉ‡∏ä‡πâ chunk ‡πÄ‡∏•‡πá‡∏Å‡∏°‡∏≤‡∏Å‡πÅ‡∏•‡∏∞ overlap ‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏≤‡∏¢"""
    
    # ‡∏•‡∏î chunk size ‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏° overlap ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ context ‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏•‡∏∞‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô
    if total_chars < 10000:
        return {
            'chunk_size': 400,
            'chunk_overlap': 250,  # 62.5% overlap - ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÑ‡∏°‡πà‡∏´‡∏≤‡∏¢
            'info': f"üìÑ ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å ({num_pages} ‡∏´‡∏ô‡πâ‡∏≤) - chunk: 400, overlap: 250 (62.5%)"
        }
    elif total_chars < 50000:
        return {
            'chunk_size': 500,
            'chunk_overlap': 300,  # 60% overlap
            'info': f"üìÑ ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Ç‡∏ô‡∏≤‡∏î‡∏Å‡∏•‡∏≤‡∏á ({num_pages} ‡∏´‡∏ô‡πâ‡∏≤) - chunk: 500, overlap: 300 (60%)"
        }
    else:
        return {
            'chunk_size': 600,
            'chunk_overlap': 360,  # 60% overlap
            'info': f"üìÑ ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà ({num_pages} ‡∏´‡∏ô‡πâ‡∏≤) - chunk: 600, overlap: 360 (60%)"
        }


def process_pdf(uploaded_file, embedding_model, base_url="http://localhost:11434"):
    """
    ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• PDF ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á Vector Store
    
    Returns:
        dict: {
            'vectorstore': FAISS vectorstore,
            'num_pages': ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏ô‡πâ‡∏≤,
            'total_chars': ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£,
            'num_chunks': ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô chunks,
            'recommended_model': model ‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
        }
    """
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
    with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
        tmp_file.write(uploaded_file.getvalue())
        tmp_file_path = tmp_file.name
    
    try:
        # ‡πÇ‡∏´‡∏•‡∏î PDF
        loader = PyPDFLoader(tmp_file_path)
        documents = loader.load()
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ç‡∏ô‡∏≤‡∏î
        total_chars = sum(len(doc.page_content) for doc in documents)
        num_pages = len(documents)
        
        # ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ model
        recommended_model = get_recommended_model(total_chars)
        
        # Dynamic chunk size
        chunk_params = get_dynamic_chunk_params(total_chars, num_pages)
        
        # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° - ‡πÉ‡∏ä‡πâ chunk ‡πÄ‡∏•‡πá‡∏Å‡πÅ‡∏•‡∏∞ overlap ‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_params['chunk_size'],
            chunk_overlap=chunk_params['chunk_overlap'],
            length_function=len,
            separators=["\n\n", "\n", " ", ""],  # ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ . ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏ï‡∏±‡∏î‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ
            keep_separator=True  # ‡πÄ‡∏Å‡πá‡∏ö separator ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á
        )
        texts = text_splitter.split_documents(documents)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á Embeddings
        embeddings = EmbeddingFactory.create_embeddings(
            model_name=embedding_model,
            base_url=base_url
        )
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á Vector Store
        vectorstore = FAISS.from_documents(texts, embeddings)
        
        return {
            'vectorstore': vectorstore,
            'num_pages': num_pages,
            'total_chars': total_chars,
            'num_chunks': len(texts),
            'recommended_model': recommended_model,
            'chunk_info': chunk_params['info']
        }
        
    finally:
        # ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
        os.unlink(tmp_file_path)


def load_vectorstore(vectorstore_path, embedding_model, base_url="http://localhost:11434"):
    """‡πÇ‡∏´‡∏•‡∏î Vector Store ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå"""
    
    embeddings = EmbeddingFactory.create_embeddings(
        model_name=embedding_model,
        base_url=base_url
    )
    
    return FAISS.load_local(
        vectorstore_path,
        embeddings,
        allow_dangerous_deserialization=True
    )


def save_vectorstore(vectorstore, vectorstore_path):
    """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Vector Store ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå"""
    vectorstore.save_local(vectorstore_path)
